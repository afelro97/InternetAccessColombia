{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:34.515597Z",
     "start_time": "2024-09-21T18:39:34.510633Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import boto3\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:34.708355Z",
     "start_time": "2024-09-21T18:39:34.618546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuración del cliente S3\n",
    "s3 = boto3.client('s3')"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:34.721001Z",
     "start_time": "2024-09-21T18:39:34.715890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Nombre del bucket y ruta en S3\n",
    "bucket_name = 'datainternetaccess'\n",
    "s3_folder = ''\n",
    "local_folder = \"data/\""
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:34.778516Z",
     "start_time": "2024-09-21T18:39:34.771314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Función para descargar los archivos de S3 manteniendo la estructura de carpetas\n",
    "def descargar_desde_s3(bucket, s3_folder, local_folder):\n",
    "    # Asegurarse de que la carpeta local existe\n",
    "    if not os.path.exists(local_folder):\n",
    "        os.makedirs(local_folder)\n",
    "\n",
    "    # Listar los objetos en el bucket y ruta especificada (en este caso, la raíz)\n",
    "    response = s3.list_objects_v2(Bucket=bucket, Prefix=s3_folder)\n",
    "\n",
    "    # Iterar sobre los archivos encontrados\n",
    "    for obj in response.get('Contents', []):\n",
    "        s3_file_path = obj['Key']\n",
    "\n",
    "        # Crear la ruta local manteniendo la estructura de carpetas de S3\n",
    "        local_file_path = os.path.join(local_folder, s3_file_path)\n",
    "\n",
    "        # Crear las carpetas necesarias en la ruta local\n",
    "        local_dir = os.path.dirname(local_file_path)\n",
    "        if not os.path.exists(local_dir):\n",
    "            os.makedirs(local_dir)\n",
    "\n",
    "        # Solo descargar si el archivo no existe localmente\n",
    "        if not os.path.exists(local_file_path):\n",
    "            print(f\"Descargando {s3_file_path} a {local_file_path}...\")\n",
    "            s3.download_file(bucket, s3_file_path, local_file_path)\n",
    "        else:\n",
    "            print(f\"El archivo {local_file_path} ya existe. No se descarga.\")\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:34.845440Z",
     "start_time": "2024-09-21T18:39:34.841759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Llamar a la función para descargar los archivos desde la raíz del bucket\n",
    "#descargar_desde_s3(bucket_name, s3_folder, local_folder)"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:34.917092Z",
     "start_time": "2024-09-21T18:39:34.903792Z"
    }
   },
   "source": [
    "spark = SparkSession.builder.appName(\"example\").getOrCreate()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/21 13:39:34 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:34.986217Z",
     "start_time": "2024-09-21T18:39:34.971697Z"
    }
   },
   "source": [
    "# Crear la sesión de Spark\n",
    "spark = SparkSession.builder.appName(\"ClasificacionUrbanoRural\").getOrCreate()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/21 13:39:34 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:35.854247Z",
     "start_time": "2024-09-21T18:39:35.039520Z"
    }
   },
   "source": [
    "# Cargar el dataset principal con POBLACIÓN DANE\n",
    "df_poblacion = spark.read.csv('data/Internet_Fijo_Penetraci_n_Municipio.csv', header=True, inferSchema=True,encoding='UTF-8')\n"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:41.017677Z",
     "start_time": "2024-09-21T18:39:35.893046Z"
    }
   },
   "source": [
    "# 2. Cargar los datasets de los departamentos con las áreas de terreno\n",
    "df_departamentos = spark.read.csv('data/deptos/*.csv', header=True, inferSchema=True, encoding='UTF-8')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:41.062281Z",
     "start_time": "2024-09-21T18:39:41.053819Z"
    }
   },
   "source": [
    "df_departamentos.printSchema()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEPARTAMENTO: integer (nullable = true)\n",
      " |-- MUNICIPIO: integer (nullable = true)\n",
      " |-- NUMERO_PREDIAL: decimal(30,0) (nullable = true)\n",
      " |-- DIRECCION: string (nullable = true)\n",
      " |-- DESTINO_ECONOMICO: string (nullable = true)\n",
      " |-- AREA_TERRENO: string (nullable = true)\n",
      " |-- AREA_CONSTRUIDA: integer (nullable = true)\n",
      " |-- NUMERO_PREDIAL_ANTERIOR: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:41.137553Z",
     "start_time": "2024-09-21T18:39:41.110635Z"
    }
   },
   "source": [
    "# 3. Convertir la columna AREA_TERRENO a tipo double (ya que es string)\n",
    "df_departamentos = df_departamentos.withColumn('AREA_TERRENO', F.col('AREA_TERRENO').cast('double'))"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:41.192016Z",
     "start_time": "2024-09-21T18:39:41.171061Z"
    }
   },
   "source": [
    "# 4. Convertir el área de metros cuadrados a kilómetros cuadrados\n",
    "df_departamentos = df_departamentos.withColumn('AREA_KM2', F.col('AREA_TERRENO') / 1000000)"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:41.273321Z",
     "start_time": "2024-09-21T18:39:41.230433Z"
    }
   },
   "source": [
    "# 5. Sumar el área total por municipio\n",
    "df_areas_municipio = df_departamentos.groupBy('DEPARTAMENTO', 'MUNICIPIO').agg(F.sum('AREA_KM2').alias('AREA_TOTAL_KM2'))"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:41.613393Z",
     "start_time": "2024-09-21T18:39:41.301889Z"
    }
   },
   "source": [
    "# 6. Verificar duplicados en los datasets\n",
    "\n",
    "# Verificar duplicados en el dataset de población\n",
    "print(\"Verificando duplicados en el dataset de población:\")\n",
    "df_poblacion.groupBy('COD_DEPARTAMENTO', 'COD_MUNICIPIO').count().filter('count > 1').show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando duplicados en el dataset de población:\n",
      "+----------------+-------------+-----+\n",
      "|COD_DEPARTAMENTO|COD_MUNICIPIO|count|\n",
      "+----------------+-------------+-----+\n",
      "|              54|        54820|   12|\n",
      "|              15|        15837|   12|\n",
      "|              86|        86885|   12|\n",
      "|              19|        19824|   12|\n",
      "|               5|         5642|   12|\n",
      "|              13|        13670|   12|\n",
      "|              15|        15507|   12|\n",
      "|              68|        68190|   12|\n",
      "|              86|        86568|   12|\n",
      "|              27|        27073|   12|\n",
      "|              13|        13433|   12|\n",
      "|              27|        27245|   12|\n",
      "|              15|        15720|   12|\n",
      "|               5|         5674|   12|\n",
      "|              23|        23555|   12|\n",
      "|              15|        15798|   12|\n",
      "|              25|        25873|   12|\n",
      "|              19|        19355|   12|\n",
      "|              25|        25740|   12|\n",
      "|               8|         8520|   12|\n",
      "+----------------+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:44.397617Z",
     "start_time": "2024-09-21T18:39:41.673783Z"
    }
   },
   "source": [
    "# Verificar duplicados en el dataset de áreas\n",
    "print(\"Verificando duplicados en el dataset de áreas:\")\n",
    "df_areas_municipio.groupBy('DEPARTAMENTO', 'MUNICIPIO').count().filter('count > 1').show()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando duplicados en el dataset de áreas:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:================================>                         (5 + 4) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-----+\n",
      "|DEPARTAMENTO|MUNICIPIO|count|\n",
      "+------------+---------+-----+\n",
      "+------------+---------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:44.579563Z",
     "start_time": "2024-09-21T18:39:44.558824Z"
    }
   },
   "source": [
    "# 7. Renombrar las columnas para que coincidan con el dataset de población\n",
    "df_areas_municipio = df_areas_municipio.withColumnRenamed('DEPARTAMENTO', 'COD_DEPARTAMENTO').withColumnRenamed('MUNICIPIO', 'COD_MUNICIPIO')"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:44.754620Z",
     "start_time": "2024-09-21T18:39:44.727409Z"
    }
   },
   "source": [
    "# 8. Asegurarse de que los códigos de departamento y municipio sean del mismo tipo (string)\n",
    "df_poblacion = df_poblacion.withColumn('COD_DEPARTAMENTO', F.col('COD_DEPARTAMENTO').cast('string'))\n",
    "df_poblacion = df_poblacion.withColumn('COD_MUNICIPIO', F.col('COD_MUNICIPIO').cast('string'))"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:44.813621Z",
     "start_time": "2024-09-21T18:39:44.772918Z"
    }
   },
   "source": [
    "df_areas_municipio = df_areas_municipio.withColumn('COD_DEPARTAMENTO', F.col('COD_DEPARTAMENTO').cast('string'))\n",
    "df_areas_municipio = df_areas_municipio.withColumn('COD_MUNICIPIO', F.col('COD_MUNICIPIO').cast('string'))"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:44.874092Z",
     "start_time": "2024-09-21T18:39:44.846185Z"
    }
   },
   "source": [
    "# 9. Verificar qué municipios de población no tienen área correspondiente\n",
    "municipios_faltantes = df_poblacion.join(df_areas_municipio, on=['COD_DEPARTAMENTO', 'COD_MUNICIPIO'], how='left_anti')"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:41:04.039292Z",
     "start_time": "2024-09-21T18:41:00.464623Z"
    }
   },
   "source": [
    "print(\"Municipios faltantes en el dataset de áreas:\")\n",
    "municipios_faltantes.select('COD_DEPARTAMENTO', 'COD_MUNICIPIO', 'MUNICIPIO').show(10, truncate=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Municipios faltantes en el dataset de áreas:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:=========================>                                (4 + 5) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+---------+\n",
      "|COD_DEPARTAMENTO|COD_MUNICIPIO|MUNICIPIO|\n",
      "+----------------+-------------+---------+\n",
      "|54              |54250        |EL TARRA |\n",
      "|25              |25594        |QUETAME  |\n",
      "|5               |5142         |CARACOLI |\n",
      "|25              |25594        |QUETAME  |\n",
      "|25              |25594        |QUETAME  |\n",
      "|54              |54250        |EL TARRA |\n",
      "|54              |54250        |EL TARRA |\n",
      "|5               |5142         |CARACOLI |\n",
      "|5               |5142         |CARACOLI |\n",
      "|25              |25594        |QUETAME  |\n",
      "+----------------+-------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:39:49.160984Z",
     "start_time": "2024-09-21T18:39:48.663444Z"
    }
   },
   "source": [
    "# Calcular la media de las áreas por departamento\n",
    "df_departamentos_mean = df_areas_municipio.groupBy('COD_DEPARTAMENTO').agg(F.mean('AREA_TOTAL_KM2').alias('mean_area'))\n",
    "\n",
    "# Unir el promedio de áreas al dataset principal\n",
    "df_completo = df_poblacion.join(df_departamentos_mean, on='COD_DEPARTAMENTO', how='left')\n",
    "\n",
    "# Rellenar los valores nulos en AREA_TOTAL_KM2 con el promedio del departamento\n",
    "df_completo = df_completo.withColumn(\n",
    "    'AREA_TOTAL_KM2',\n",
    "    F.when(F.col('AREA_TOTAL_KM2').isNull(), F.col('mean_area')).otherwise(F.col('AREA_TOTAL_KM2'))\n",
    ")"
   ],
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `AREA_TOTAL_KM2` cannot be resolved. Did you mean one of the following? [`AÑO`, `DEPARTAMENTO`, `TRIMESTRE`, `COD_MUNICIPIO`, `INDICE`].;\n'Project [COD_DEPARTAMENTO#406, AÑO#256, TRIMESTRE#257, DEPARTAMENTO#259, COD_MUNICIPIO#416, MUNICIPIO#261, No. ACCESOS FIJOS A INTERNET#262, POBLACIÓN DANE#263, INDICE#264, mean_area#468, CASE WHEN isnull('AREA_TOTAL_KM2) THEN mean_area#468 ELSE 'AREA_TOTAL_KM2 END AS AREA_TOTAL_KM2#481]\n+- Project [COD_DEPARTAMENTO#406, AÑO#256, TRIMESTRE#257, DEPARTAMENTO#259, COD_MUNICIPIO#416, MUNICIPIO#261, No. ACCESOS FIJOS A INTERNET#262, POBLACIÓN DANE#263, INDICE#264, mean_area#468]\n   +- Join LeftOuter, (COD_DEPARTAMENTO#406 = COD_DEPARTAMENTO#426)\n      :- Project [AÑO#256, TRIMESTRE#257, COD_DEPARTAMENTO#406, DEPARTAMENTO#259, cast(COD_MUNICIPIO#260 as string) AS COD_MUNICIPIO#416, MUNICIPIO#261, No. ACCESOS FIJOS A INTERNET#262, POBLACIÓN DANE#263, INDICE#264]\n      :  +- Project [AÑO#256, TRIMESTRE#257, cast(COD_DEPARTAMENTO#258 as string) AS COD_DEPARTAMENTO#406, DEPARTAMENTO#259, COD_MUNICIPIO#260, MUNICIPIO#261, No. ACCESOS FIJOS A INTERNET#262, POBLACIÓN DANE#263, INDICE#264]\n      :     +- Relation [AÑO#256,TRIMESTRE#257,COD_DEPARTAMENTO#258,DEPARTAMENTO#259,COD_MUNICIPIO#260,MUNICIPIO#261,No. ACCESOS FIJOS A INTERNET#262,POBLACIÓN DANE#263,INDICE#264] csv\n      +- Aggregate [COD_DEPARTAMENTO#426], [COD_DEPARTAMENTO#426, avg(AREA_TOTAL_KM2#337) AS mean_area#468]\n         +- Project [COD_DEPARTAMENTO#426, cast(COD_MUNICIPIO#402 as string) AS COD_MUNICIPIO#430, AREA_TOTAL_KM2#337]\n            +- Project [cast(COD_DEPARTAMENTO#398 as string) AS COD_DEPARTAMENTO#426, COD_MUNICIPIO#402, AREA_TOTAL_KM2#337]\n               +- Project [COD_DEPARTAMENTO#398, MUNICIPIO#292 AS COD_MUNICIPIO#402, AREA_TOTAL_KM2#337]\n                  +- Project [DEPARTAMENTO#291 AS COD_DEPARTAMENTO#398, MUNICIPIO#292, AREA_TOTAL_KM2#337]\n                     +- Aggregate [DEPARTAMENTO#291, MUNICIPIO#292], [DEPARTAMENTO#291, MUNICIPIO#292, sum(AREA_KM2#317) AS AREA_TOTAL_KM2#337]\n                        +- Project [DEPARTAMENTO#291, MUNICIPIO#292, NUMERO_PREDIAL#293, DIRECCION#294, DESTINO_ECONOMICO#295, AREA_TERRENO#307, AREA_CONSTRUIDA#297, NUMERO_PREDIAL_ANTERIOR#298, (AREA_TERRENO#307 / cast(1000000 as double)) AS AREA_KM2#317]\n                           +- Project [DEPARTAMENTO#291, MUNICIPIO#292, NUMERO_PREDIAL#293, DIRECCION#294, DESTINO_ECONOMICO#295, cast(AREA_TERRENO#296 as double) AS AREA_TERRENO#307, AREA_CONSTRUIDA#297, NUMERO_PREDIAL_ANTERIOR#298]\n                              +- Relation [DEPARTAMENTO#291,MUNICIPIO#292,NUMERO_PREDIAL#293,DIRECCION#294,DESTINO_ECONOMICO#295,AREA_TERRENO#296,AREA_CONSTRUIDA#297,NUMERO_PREDIAL_ANTERIOR#298] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[43], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m df_completo \u001B[38;5;241m=\u001B[39m df_poblacion\u001B[38;5;241m.\u001B[39mjoin(df_departamentos_mean, on\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCOD_DEPARTAMENTO\u001B[39m\u001B[38;5;124m'\u001B[39m, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Rellenar los valores nulos en AREA_TOTAL_KM2 con el promedio del departamento\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m df_completo \u001B[38;5;241m=\u001B[39m \u001B[43mdf_completo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwithColumn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mAREA_TOTAL_KM2\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwhen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcol\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mAREA_TOTAL_KM2\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43misNull\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcol\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmean_area\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43motherwise\u001B[49m\u001B[43m(\u001B[49m\u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcol\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mAREA_TOTAL_KM2\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/InternetAccessColombia/lib/python3.10/site-packages/pyspark/sql/dataframe.py:5176\u001B[0m, in \u001B[0;36mDataFrame.withColumn\u001B[0;34m(self, colName, col)\u001B[0m\n\u001B[1;32m   5171\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(col, Column):\n\u001B[1;32m   5172\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n\u001B[1;32m   5173\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNOT_COLUMN\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   5174\u001B[0m         message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcol\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(col)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n\u001B[1;32m   5175\u001B[0m     )\n\u001B[0;32m-> 5176\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwithColumn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcolName\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcol\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jc\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
      "File \u001B[0;32m~/.virtualenvs/InternetAccessColombia/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1316\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1319\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1321\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1322\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1323\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1325\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/.virtualenvs/InternetAccessColombia/lib/python3.10/site-packages/pyspark/errors/exceptions/captured.py:185\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    181\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 185\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    187\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `AREA_TOTAL_KM2` cannot be resolved. Did you mean one of the following? [`AÑO`, `DEPARTAMENTO`, `TRIMESTRE`, `COD_MUNICIPIO`, `INDICE`].;\n'Project [COD_DEPARTAMENTO#406, AÑO#256, TRIMESTRE#257, DEPARTAMENTO#259, COD_MUNICIPIO#416, MUNICIPIO#261, No. ACCESOS FIJOS A INTERNET#262, POBLACIÓN DANE#263, INDICE#264, mean_area#468, CASE WHEN isnull('AREA_TOTAL_KM2) THEN mean_area#468 ELSE 'AREA_TOTAL_KM2 END AS AREA_TOTAL_KM2#481]\n+- Project [COD_DEPARTAMENTO#406, AÑO#256, TRIMESTRE#257, DEPARTAMENTO#259, COD_MUNICIPIO#416, MUNICIPIO#261, No. ACCESOS FIJOS A INTERNET#262, POBLACIÓN DANE#263, INDICE#264, mean_area#468]\n   +- Join LeftOuter, (COD_DEPARTAMENTO#406 = COD_DEPARTAMENTO#426)\n      :- Project [AÑO#256, TRIMESTRE#257, COD_DEPARTAMENTO#406, DEPARTAMENTO#259, cast(COD_MUNICIPIO#260 as string) AS COD_MUNICIPIO#416, MUNICIPIO#261, No. ACCESOS FIJOS A INTERNET#262, POBLACIÓN DANE#263, INDICE#264]\n      :  +- Project [AÑO#256, TRIMESTRE#257, cast(COD_DEPARTAMENTO#258 as string) AS COD_DEPARTAMENTO#406, DEPARTAMENTO#259, COD_MUNICIPIO#260, MUNICIPIO#261, No. ACCESOS FIJOS A INTERNET#262, POBLACIÓN DANE#263, INDICE#264]\n      :     +- Relation [AÑO#256,TRIMESTRE#257,COD_DEPARTAMENTO#258,DEPARTAMENTO#259,COD_MUNICIPIO#260,MUNICIPIO#261,No. ACCESOS FIJOS A INTERNET#262,POBLACIÓN DANE#263,INDICE#264] csv\n      +- Aggregate [COD_DEPARTAMENTO#426], [COD_DEPARTAMENTO#426, avg(AREA_TOTAL_KM2#337) AS mean_area#468]\n         +- Project [COD_DEPARTAMENTO#426, cast(COD_MUNICIPIO#402 as string) AS COD_MUNICIPIO#430, AREA_TOTAL_KM2#337]\n            +- Project [cast(COD_DEPARTAMENTO#398 as string) AS COD_DEPARTAMENTO#426, COD_MUNICIPIO#402, AREA_TOTAL_KM2#337]\n               +- Project [COD_DEPARTAMENTO#398, MUNICIPIO#292 AS COD_MUNICIPIO#402, AREA_TOTAL_KM2#337]\n                  +- Project [DEPARTAMENTO#291 AS COD_DEPARTAMENTO#398, MUNICIPIO#292, AREA_TOTAL_KM2#337]\n                     +- Aggregate [DEPARTAMENTO#291, MUNICIPIO#292], [DEPARTAMENTO#291, MUNICIPIO#292, sum(AREA_KM2#317) AS AREA_TOTAL_KM2#337]\n                        +- Project [DEPARTAMENTO#291, MUNICIPIO#292, NUMERO_PREDIAL#293, DIRECCION#294, DESTINO_ECONOMICO#295, AREA_TERRENO#307, AREA_CONSTRUIDA#297, NUMERO_PREDIAL_ANTERIOR#298, (AREA_TERRENO#307 / cast(1000000 as double)) AS AREA_KM2#317]\n                           +- Project [DEPARTAMENTO#291, MUNICIPIO#292, NUMERO_PREDIAL#293, DIRECCION#294, DESTINO_ECONOMICO#295, cast(AREA_TERRENO#296 as double) AS AREA_TERRENO#307, AREA_CONSTRUIDA#297, NUMERO_PREDIAL_ANTERIOR#298]\n                              +- Relation [DEPARTAMENTO#291,MUNICIPIO#292,NUMERO_PREDIAL#293,DIRECCION#294,DESTINO_ECONOMICO#295,AREA_TERRENO#296,AREA_CONSTRUIDA#297,NUMERO_PREDIAL_ANTERIOR#298] csv\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:42:34.860479Z",
     "start_time": "2024-09-21T18:42:34.852965Z"
    }
   },
   "cell_type": "code",
   "source": "df_areas_municipio.printSchema()",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COD_DEPARTAMENTO: string (nullable = true)\n",
      " |-- COD_MUNICIPIO: string (nullable = true)\n",
      " |-- AREA_TOTAL_KM2: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Calcular la densidad poblacional\n",
    "df_completo = df_completo.withColumn('densidad_poblacional', F.col('POBLACIÓN DANE') / F.col('AREA_TOTAL_KM2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Clasificar como Urbano o Rural según la densidad poblacional\n",
    "df_completo = df_completo.withColumn(\n",
    "    'Clasificacion',\n",
    "    F.when(F.col('densidad_poblacional') >= 100, 'Urbano').otherwise('Rural')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:===================================>                    (12 + 7) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de municipios en el dataset completo: 832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 13. Verificar el número total de municipios en el dataset completo\n",
    "num_municipios = df_completo.select('COD_MUNICIPIO').distinct().count()\n",
    "print(f\"Número total de municipios en el dataset completo: {num_municipios}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 14. Guardar el nuevo dataset clasificado en la carpeta transformaciones\n",
    "df_completo.write.csv('data/deptos/transformaciones/transformaciones.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "municipios_faltantes_data = municipios_faltantes.select('COD_DEPARTAMENTO', 'COD_MUNICIPIO', 'MUNICIPIO') \\\n",
    "    .write.csv('data/deptos/transformaciones/municipios_faltantes.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta donde están los archivos CSV de los departamentos\n",
    "ruta_deptos = 'data/deptos/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17_CALDAS_R1.csv',\n",
       " '44_GUAJIRA_R1.csv',\n",
       " '88_SAN_ANDRES_R1.csv',\n",
       " '23_CORDOBA_R1.csv',\n",
       " '73_TOLIMA_R1.csv',\n",
       " '13_BOLIVAR_R1.csv',\n",
       " '50_META_R1.csv',\n",
       " '47_MAGDALENA_R1.csv',\n",
       " '18_CAQUETA_R1.csv',\n",
       " '95_GUAVIARE_R1.csv',\n",
       " '97_VAUPES_R1.csv',\n",
       " '54_N_SANTANDER_R1.csv',\n",
       " '68_SANTANDER_R1.csv',\n",
       " '41_HUILA_R1.csv',\n",
       " '19_CAUCA_R1.csv',\n",
       " '81_ARAUCA_R1.csv',\n",
       " '15_BOYACA_R1.csv',\n",
       " '70_SUCRE_R1.csv',\n",
       " '99_VICHADA_R1.csv',\n",
       " '63_QUINDIO_R1.csv',\n",
       " '76_VALLE_R1.csv',\n",
       " '66_RISARALDA_R1.csv',\n",
       " '08_ATLANTICO_R1.csv',\n",
       " '27_CHOCO_R1.csv',\n",
       " '52_NARINO_R1.csv',\n",
       " '91_AMAZONAS_R1.csv',\n",
       " '85_CASANARE_R1.csv',\n",
       " '20_CESAR_R1.csv',\n",
       " '94_GUAINIA_R1.csv',\n",
       " '25_CUNDINAMARCA_R1.csv',\n",
       " '86_PUTUMAYO_R1.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listar todos los archivos en la carpeta, excluyendo los que están en la subcarpeta transformaciones\n",
    "archivos_deptos = [archivo for archivo in os.listdir(ruta_deptos) if os.path.isfile(os.path.join(ruta_deptos, archivo))]\n",
    "archivos_deptos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo 17_CALDAS_R1.csv tiene 17045 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 44_GUAJIRA_R1.csv tiene 25661 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 88_SAN_ANDRES_R1.csv tiene 2004 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 23_CORDOBA_R1.csv tiene 48586 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 73_TOLIMA_R1.csv tiene 42153 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 13_BOLIVAR_R1.csv tiene 31775 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 50_META_R1.csv tiene 35206 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 47_MAGDALENA_R1.csv tiene 46997 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 18_CAQUETA_R1.csv tiene 10861 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 95_GUAVIARE_R1.csv tiene 2868 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 97_VAUPES_R1.csv tiene 1181 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 54_N_SANTANDER_R1.csv tiene 25412 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 68_SANTANDER_R1.csv tiene 11898 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 41_HUILA_R1.csv tiene 37131 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 19_CAUCA_R1.csv tiene 60111 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 81_ARAUCA_R1.csv tiene 10783 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 15_BOYACA_R1.csv tiene 22828 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 70_SUCRE_R1.csv tiene 26694 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 99_VICHADA_R1.csv tiene 5353 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 63_QUINDIO_R1.csv tiene 3516 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 76_VALLE_R1.csv tiene 32469 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 66_RISARALDA_R1.csv tiene 5132 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 08_ATLANTICO_R1.csv tiene 15497 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 27_CHOCO_R1.csv tiene 40345 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 52_NARINO_R1.csv tiene 26283 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 91_AMAZONAS_R1.csv tiene 1767 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 85_CASANARE_R1.csv tiene 12003 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 20_CESAR_R1.csv tiene 50388 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 94_GUAINIA_R1.csv tiene 1405 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 25_CUNDINAMARCA_R1.csv tiene 9489 valores nulos o cero en AREA_TERRENO.\n",
      "El archivo 86_PUTUMAYO_R1.csv tiene 5137 valores nulos o cero en AREA_TERRENO.\n"
     ]
    }
   ],
   "source": [
    "# Revisar si hay valores faltantes en cada archivo de departamentos\n",
    "for archivo in archivos_deptos:\n",
    "    # Cargar el archivo CSV\n",
    "    df_depto = spark.read.csv(os.path.join(ruta_deptos, archivo), header=True, inferSchema=True, encoding='UTF-8')\n",
    "    \n",
    "    # Convertir AREA_TERRENO a double (si no lo has hecho antes)\n",
    "    df_depto = df_depto.withColumn('AREA_TERRENO', F.col('AREA_TERRENO').cast('double'))\n",
    "\n",
    "    # Verificar si hay valores nulos o si AREA_TERRENO es igual a 0\n",
    "    valores_faltantes = df_depto.filter(F.col('AREA_TERRENO').isNull() | (F.col('AREA_TERRENO') == 0))\n",
    "\n",
    "    # Contar cuántos valores faltantes hay\n",
    "    num_faltantes = valores_faltantes.count()\n",
    "\n",
    "    if num_faltantes > 0:\n",
    "        print(f\"El archivo {archivo} tiene {num_faltantes} valores nulos o cero en AREA_TERRENO.\")\n",
    "    else:\n",
    "        print(f\"El archivo {archivo} no tiene valores nulos en AREA_TERRENO.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Revisar si hay valores faltantes en cada archivo de departamentos\n",
    "for archivo in archivos_deptos:\n",
    "    # Cargar el archivo CSV\n",
    "    df_depto = spark.read.csv(os.path.join(ruta_deptos, archivo), header=True, inferSchema=True, encoding='UTF-8')\n",
    "    \n",
    "    # Convertir AREA_TERRENO a double (si no lo has hecho antes)\n",
    "    df_depto = df_depto.withColumn('AREA_TERRENO', F.col('AREA_TERRENO').cast('double'))\n",
    "\n",
    "    # Verificar si hay valores nulos o si AREA_TERRENO es igual a 0\n",
    "    valores_faltantes = df_depto.filter(F.col('AREA_TERRENO').isNull() | (F.col('AREA_TERRENO') == 0))\n",
    "\n",
    "    # Contar cuántos valores faltantes hay\n",
    "    num_faltantes = valores_faltantes.count()\n",
    "\n",
    "    if num_faltantes > 0:\n",
    "        valores_faltantes.write.csv(f'data/deptos/transformaciones/{archivo}_valores_faltantes.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
